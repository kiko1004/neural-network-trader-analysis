{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impaired-butterfly",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "herbal-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tpot\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vulnerable-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = yf.Ticker(\"aapl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "healthy-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = msft.history(period = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thousand-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-manufacturer",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loved-multimedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.100326</td>\n",
       "      <td>0.100762</td>\n",
       "      <td>0.100326</td>\n",
       "      <td>0.100326</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.095528</td>\n",
       "      <td>0.095528</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.088548</td>\n",
       "      <td>0.088548</td>\n",
       "      <td>0.088112</td>\n",
       "      <td>0.088112</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.090293</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.090293</td>\n",
       "      <td>0.090293</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.092911</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.092911</td>\n",
       "      <td>0.092911</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>169.943485</td>\n",
       "      <td>174.777323</td>\n",
       "      <td>169.294303</td>\n",
       "      <td>174.557602</td>\n",
       "      <td>115541600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>173.788575</td>\n",
       "      <td>174.617520</td>\n",
       "      <td>172.090741</td>\n",
       "      <td>174.387817</td>\n",
       "      <td>86213900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>174.527647</td>\n",
       "      <td>175.656214</td>\n",
       "      <td>173.109456</td>\n",
       "      <td>175.616257</td>\n",
       "      <td>84914300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>174.257984</td>\n",
       "      <td>176.015754</td>\n",
       "      <td>171.900986</td>\n",
       "      <td>172.679993</td>\n",
       "      <td>89418100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10375</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>171.679993</td>\n",
       "      <td>174.100006</td>\n",
       "      <td>170.679993</td>\n",
       "      <td>172.389999</td>\n",
       "      <td>82391400</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10376 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close     Volume  \\\n",
       "0     1980-12-12    0.100326    0.100762    0.100326    0.100326  469033600   \n",
       "1     1980-12-15    0.095528    0.095528    0.095092    0.095092  175884800   \n",
       "2     1980-12-16    0.088548    0.088548    0.088112    0.088112  105728000   \n",
       "3     1980-12-17    0.090293    0.090729    0.090293    0.090293   86441600   \n",
       "4     1980-12-18    0.092911    0.093347    0.092911    0.092911   73449600   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "10371 2022-01-31  169.943485  174.777323  169.294303  174.557602  115541600   \n",
       "10372 2022-02-01  173.788575  174.617520  172.090741  174.387817   86213900   \n",
       "10373 2022-02-02  174.527647  175.656214  173.109456  175.616257   84914300   \n",
       "10374 2022-02-03  174.257984  176.015754  171.900986  172.679993   89418100   \n",
       "10375 2022-02-04  171.679993  174.100006  170.679993  172.389999   82391400   \n",
       "\n",
       "       Dividends  Stock Splits  \n",
       "0           0.00           0.0  \n",
       "1           0.00           0.0  \n",
       "2           0.00           0.0  \n",
       "3           0.00           0.0  \n",
       "4           0.00           0.0  \n",
       "...          ...           ...  \n",
       "10371       0.00           0.0  \n",
       "10372       0.00           0.0  \n",
       "10373       0.00           0.0  \n",
       "10374       0.00           0.0  \n",
       "10375       0.22           0.0  \n",
       "\n",
       "[10376 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "impossible-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade = df[df['Date'] > '2010-01-01'].reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brave-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['Close_pct_change'] = df_decade['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriental-salon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Close_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>6.526949</td>\n",
       "      <td>6.559671</td>\n",
       "      <td>6.494839</td>\n",
       "      <td>6.544686</td>\n",
       "      <td>493729600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>6.562730</td>\n",
       "      <td>6.593005</td>\n",
       "      <td>6.521445</td>\n",
       "      <td>6.556002</td>\n",
       "      <td>601904800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>6.556004</td>\n",
       "      <td>6.581998</td>\n",
       "      <td>6.444994</td>\n",
       "      <td>6.451722</td>\n",
       "      <td>552160000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>6.475575</td>\n",
       "      <td>6.483220</td>\n",
       "      <td>6.393005</td>\n",
       "      <td>6.439794</td>\n",
       "      <td>477131200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>6.431231</td>\n",
       "      <td>6.483219</td>\n",
       "      <td>6.393311</td>\n",
       "      <td>6.482607</td>\n",
       "      <td>447610800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>169.943485</td>\n",
       "      <td>174.777323</td>\n",
       "      <td>169.294303</td>\n",
       "      <td>174.557602</td>\n",
       "      <td>115541600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>173.788575</td>\n",
       "      <td>174.617520</td>\n",
       "      <td>172.090741</td>\n",
       "      <td>174.387817</td>\n",
       "      <td>86213900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>174.527647</td>\n",
       "      <td>175.656214</td>\n",
       "      <td>173.109456</td>\n",
       "      <td>175.616257</td>\n",
       "      <td>84914300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>174.257984</td>\n",
       "      <td>176.015754</td>\n",
       "      <td>171.900986</td>\n",
       "      <td>172.679993</td>\n",
       "      <td>89418100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>171.679993</td>\n",
       "      <td>174.100006</td>\n",
       "      <td>170.679993</td>\n",
       "      <td>172.389999</td>\n",
       "      <td>82391400</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close     Volume  \\\n",
       "0    2010-01-04    6.526949    6.559671    6.494839    6.544686  493729600   \n",
       "1    2010-01-05    6.562730    6.593005    6.521445    6.556002  601904800   \n",
       "2    2010-01-06    6.556004    6.581998    6.444994    6.451722  552160000   \n",
       "3    2010-01-07    6.475575    6.483220    6.393005    6.439794  477131200   \n",
       "4    2010-01-08    6.431231    6.483219    6.393311    6.482607  447610800   \n",
       "...         ...         ...         ...         ...         ...        ...   \n",
       "3040 2022-01-31  169.943485  174.777323  169.294303  174.557602  115541600   \n",
       "3041 2022-02-01  173.788575  174.617520  172.090741  174.387817   86213900   \n",
       "3042 2022-02-02  174.527647  175.656214  173.109456  175.616257   84914300   \n",
       "3043 2022-02-03  174.257984  176.015754  171.900986  172.679993   89418100   \n",
       "3044 2022-02-04  171.679993  174.100006  170.679993  172.389999   82391400   \n",
       "\n",
       "      Dividends  Stock Splits  Close_pct_change  \n",
       "0          0.00           0.0               NaN  \n",
       "1          0.00           0.0          0.001729  \n",
       "2          0.00           0.0         -0.015906  \n",
       "3          0.00           0.0         -0.001849  \n",
       "4          0.00           0.0          0.006648  \n",
       "...         ...           ...               ...  \n",
       "3040       0.00           0.0          0.026126  \n",
       "3041       0.00           0.0         -0.000973  \n",
       "3042       0.00           0.0          0.007044  \n",
       "3043       0.00           0.0         -0.016720  \n",
       "3044       0.22           0.0         -0.001679  \n",
       "\n",
       "[3045 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hazardous-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade[\"Price_weekly_increase_future\"] = df_decade['Close'].pct_change(periods = -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "charming-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade[\"Close_daily_increase_past\"] = df_decade['Close'].pct_change(periods = 1)\n",
    "df_decade[\"Volume_daily_increase_past\"] = df_decade['Volume'].pct_change(periods = 1)\n",
    "df_decade[\"Open_daily_increase_past\"] = df_decade['Open'].pct_change(periods = 1)\n",
    "df_decade[\"High_daily_increase_past\"] = df_decade['High'].pct_change(periods = 1)\n",
    "df_decade[\"Low_daily_increase_past\"] = df_decade['Low'].pct_change(periods = 1)\n",
    "\n",
    "df_decade[\"Close_weekly_increase_past\"] = df_decade['Close'].pct_change(periods = 5)\n",
    "df_decade[\"Volume_weekly_increase_past\"] = df_decade['Volume'].pct_change(periods = 5)\n",
    "df_decade[\"Open_weekly_increase_past\"] = df_decade['Open'].pct_change(periods = 5)\n",
    "df_decade[\"High_weekly_increase_past\"] = df_decade['High'].pct_change(periods = 5)\n",
    "df_decade[\"Low_weekly_increase_past\"] = df_decade['Low'].pct_change(periods = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "greatest-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['High_Low_range'] = df_decade[\"High\"] - df_decade[\"Low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "remarkable-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_week(day):\n",
    "    start = day - timedelta(days=day.weekday())\n",
    "    if day == start:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def end_week(day):\n",
    "    start = day - timedelta(days=day.weekday())\n",
    "    end = start + timedelta(days=4)\n",
    "    if day == end:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "governing-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['is_start_week'] = df_decade['Date'].apply(start_week)\n",
    "df_decade['is_end_week'] = df_decade['Date'].apply(end_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "painted-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['is_dividends'] = np.where(df_decade['Dividends'] > 0, 1, 0)\n",
    "df_decade['is_stock_splits'] = np.where(df_decade['Stock Splits'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "invalid-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['Price_weekly_increase_future'] = df_decade['Price_weekly_increase_future'].apply(lambda x: -1*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['Month'] = df_decade[\"Date\"].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biological-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummie_month = pd.get_dummies(df_decade['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "expensive-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummie_month.columns = [f\"Month_{col}\" for col in df_dummie_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blocked-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade = df_decade.join(df_dummie_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advance-philosophy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
       "       'Stock Splits', 'Close_pct_change', 'Price_weekly_increase_future',\n",
       "       'Close_daily_increase_past', 'Volume_daily_increase_past',\n",
       "       'Open_daily_increase_past', 'High_daily_increase_past',\n",
       "       'Low_daily_increase_past', 'Close_weekly_increase_past',\n",
       "       'Volume_weekly_increase_past', 'Open_weekly_increase_past',\n",
       "       'High_weekly_increase_past', 'Low_weekly_increase_past',\n",
       "       'High_Low_range', 'is_start_week', 'is_end_week', 'is_dividends',\n",
       "       'is_stock_splits', 'Month', 'Month_1', 'Month_2', 'Month_3', 'Month_4',\n",
       "       'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9', 'Month_10',\n",
       "       'Month_11', 'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decade.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "injured-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.018562\n",
       "1   -0.032062\n",
       "2   -0.001519\n",
       "3   -0.005491\n",
       "4   -0.029379\n",
       "Name: Price_weekly_increase_future, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decade['Price_weekly_increase_future'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "perfect-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade = df_decade.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "greek-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df_decade['Price_weekly_increase_future'] >=0) & (df_decade['Price_weekly_increase_future'] < 0.001),\n",
    "    (df_decade['Price_weekly_increase_future'] >=0.001) & (df_decade['Price_weekly_increase_future'] < 0.01),\n",
    "    (df_decade['Price_weekly_increase_future'] >=0.01 ) & ( df_decade['Price_weekly_increase_future'] < 0.02),\n",
    "    (df_decade['Price_weekly_increase_future'] >=0.02 ) & ( df_decade['Price_weekly_increase_future'] < 0.03),\n",
    "    (df_decade['Price_weekly_increase_future'] >=0.03),\n",
    "    (df_decade['Price_weekly_increase_future'] <=0 ) & ( df_decade['Price_weekly_increase_future'] > -0.001),\n",
    "    (df_decade['Price_weekly_increase_future'] <=-0.001 ) & ( df_decade['Price_weekly_increase_future'] > -0.01),\n",
    "    (df_decade['Price_weekly_increase_future'] <=-0.01 ) & ( df_decade['Price_weekly_increase_future'] > -0.02),\n",
    "    (df_decade['Price_weekly_increase_future'] <=-0.02 ) & ( df_decade['Price_weekly_increase_future'] > -0.03),\n",
    "    (df_decade['Price_weekly_increase_future'] <=-0.03),\n",
    "    \n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['insignificant increase < 0.1%', 'less than 1% increase', '1% - 2%', '2% - 3%', '3%+',\n",
    "         'insignificant decrease > -0.1%', 'less than 1% decrease', 'decrease 1%-2%', 'decrease 2%-3%', 'decrease more that 3%']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_decade['tier'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-glenn",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-model",
   "metadata": {},
   "source": [
    "#### Model Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "announced-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Close_pct_change', 'Volume_daily_increase_past',\n",
    "       'Open_daily_increase_past', 'High_daily_increase_past',\n",
    "       'Low_daily_increase_past', 'Close_weekly_increase_past',\n",
    "       'Volume_weekly_increase_past', 'Open_weekly_increase_past',\n",
    "       'High_weekly_increase_past', 'Low_weekly_increase_past',\n",
    "       'High_Low_range', 'is_start_week', 'is_end_week', 'is_dividends',\n",
    "       'is_stock_splits', 'Month', 'Month_1', 'Month_2', 'Month_3', 'Month_4',\n",
    "       'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9', 'Month_10',\n",
    "       'Month_11', 'Month_12']\n",
    "target = ['tier']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-liberia",
   "metadata": {},
   "source": [
    "#### Model One-V-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "psychological-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_one_v = ['did_increase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lyric-organization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5        True\n",
       "6        True\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "        ...  \n",
       "3035     True\n",
       "3036     True\n",
       "3037     True\n",
       "3038     True\n",
       "3039     True\n",
       "Name: Price_weekly_increase_future, Length: 3035, dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decade['Price_weekly_increase_future'] >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "opposite-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['did_increase'] = np.where(df_decade['Price_weekly_increase_future'] >= 0, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hungarian-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1785\n",
       "0    1250\n",
       "Name: did_increase, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decade['did_increase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-terror",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "renewable-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NN(target, model_name, epochs):\n",
    "    X = df_decade[features].values\n",
    "    y = df_decade[target].values\n",
    "    _array =  np.unique(y, return_counts = True)[0]\n",
    "    y_indices = [list(_array).index(i) for i in y]\n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
    "        X,\n",
    "        y_indices,\n",
    "        test_size=0.20,\n",
    "        random_state=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    X_validation_numpy = np.asarray(X_validation)\n",
    "    X_train_numpy = np.asarray(X_train)\n",
    "    Y_train_numpy = np.asarray(Y_train).astype('int32')\n",
    "    Y_validation_numpy = np.asarray(Y_validation).astype('int32')\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(655, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(len(_array), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_numpy, Y_train_numpy, epochs=epochs)\n",
    "    model.evaluate(X_validation_numpy, Y_validation_numpy, verbose=2)\n",
    "    model.summary()\n",
    "\n",
    "    model.save(model_name)\n",
    "    print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "theoretical-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5898\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5906\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5906\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.5972\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.6058\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6137\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6079\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6075\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6190\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6219\n",
      "19/19 - 1s - loss: 0.7268 - accuracy: 0.5618 - 627ms/epoch - 33ms/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 28)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 655)               18995     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 655)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1312      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,307\n",
      "Trainable params: 20,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: if_increase\\assets\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "build_NN(target_one_v, 'if_increase', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "protective-chest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.1517 - accuracy: 0.2002\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0984 - accuracy: 0.2348\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0889 - accuracy: 0.2290\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0719 - accuracy: 0.2335\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0612 - accuracy: 0.2327\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0531 - accuracy: 0.2414\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0437 - accuracy: 0.2418\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0284 - accuracy: 0.2438\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0253 - accuracy: 0.2488\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0144 - accuracy: 0.2500\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0127 - accuracy: 0.2582\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0066 - accuracy: 0.2525\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0049 - accuracy: 0.2628\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9978 - accuracy: 0.2603\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9857 - accuracy: 0.2648\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9807 - accuracy: 0.2689\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9738 - accuracy: 0.2648\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9624 - accuracy: 0.2764\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9655 - accuracy: 0.2710\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9540 - accuracy: 0.2722\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9506 - accuracy: 0.2731\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9429 - accuracy: 0.2718\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9426 - accuracy: 0.2735\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9350 - accuracy: 0.2858\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9285 - accuracy: 0.2871\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9221 - accuracy: 0.2813\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9181 - accuracy: 0.2887\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9127 - accuracy: 0.2838\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9046 - accuracy: 0.2974\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.9063 - accuracy: 0.2916\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8928 - accuracy: 0.2908\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8852 - accuracy: 0.2912\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8902 - accuracy: 0.2941\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8828 - accuracy: 0.3064\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8806 - accuracy: 0.2986\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8655 - accuracy: 0.3093\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8782 - accuracy: 0.2862\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8564 - accuracy: 0.3105\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8633 - accuracy: 0.3044\n",
      "Epoch 40/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8542 - accuracy: 0.3081\n",
      "Epoch 41/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8476 - accuracy: 0.3130\n",
      "Epoch 42/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8471 - accuracy: 0.3138\n",
      "Epoch 43/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8354 - accuracy: 0.3077\n",
      "Epoch 44/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8269 - accuracy: 0.3184\n",
      "Epoch 45/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8357 - accuracy: 0.3171\n",
      "Epoch 46/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8224 - accuracy: 0.3192\n",
      "Epoch 47/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8220 - accuracy: 0.3200\n",
      "Epoch 48/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8137 - accuracy: 0.3348\n",
      "Epoch 49/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8094 - accuracy: 0.3311\n",
      "Epoch 50/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8205 - accuracy: 0.3262\n",
      "Epoch 51/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8057 - accuracy: 0.3344\n",
      "Epoch 52/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7967 - accuracy: 0.3328\n",
      "Epoch 53/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.8080 - accuracy: 0.3270\n",
      "Epoch 54/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7882 - accuracy: 0.3344\n",
      "Epoch 55/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7828 - accuracy: 0.3423\n",
      "Epoch 56/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7836 - accuracy: 0.3348\n",
      "Epoch 57/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7762 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7840 - accuracy: 0.3406\n",
      "Epoch 59/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7706 - accuracy: 0.3386\n",
      "Epoch 60/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7703 - accuracy: 0.3394\n",
      "Epoch 61/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7561 - accuracy: 0.3513\n",
      "Epoch 62/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7524 - accuracy: 0.3468\n",
      "Epoch 63/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7588 - accuracy: 0.3460\n",
      "Epoch 64/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7497 - accuracy: 0.3567\n",
      "Epoch 65/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7418 - accuracy: 0.3501\n",
      "Epoch 66/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7452 - accuracy: 0.3456\n",
      "Epoch 67/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7428 - accuracy: 0.3509\n",
      "Epoch 68/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7345 - accuracy: 0.3542\n",
      "Epoch 69/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7368 - accuracy: 0.3546\n",
      "Epoch 70/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7215 - accuracy: 0.3579\n",
      "Epoch 71/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7296 - accuracy: 0.3558\n",
      "Epoch 72/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7257 - accuracy: 0.3661\n",
      "Epoch 73/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7309 - accuracy: 0.3571\n",
      "Epoch 74/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7266 - accuracy: 0.3550\n",
      "Epoch 75/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7258 - accuracy: 0.3554\n",
      "Epoch 76/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7107 - accuracy: 0.3637\n",
      "Epoch 77/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7038 - accuracy: 0.3719\n",
      "Epoch 78/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7078 - accuracy: 0.3707\n",
      "Epoch 79/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6968 - accuracy: 0.3620\n",
      "Epoch 80/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.7019 - accuracy: 0.3810\n",
      "Epoch 81/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6943 - accuracy: 0.3682\n",
      "Epoch 82/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6881 - accuracy: 0.3727\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6861 - accuracy: 0.3736\n",
      "Epoch 84/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6904 - accuracy: 0.3814\n",
      "Epoch 85/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6902 - accuracy: 0.3727\n",
      "Epoch 86/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6838 - accuracy: 0.3764\n",
      "Epoch 87/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6754 - accuracy: 0.3826\n",
      "Epoch 88/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6664 - accuracy: 0.3843\n",
      "Epoch 89/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6682 - accuracy: 0.3797\n",
      "Epoch 90/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6593 - accuracy: 0.3818\n",
      "Epoch 91/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6650 - accuracy: 0.3871\n",
      "Epoch 92/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6565 - accuracy: 0.3764\n",
      "Epoch 93/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6537 - accuracy: 0.3834\n",
      "Epoch 94/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6481 - accuracy: 0.3904\n",
      "Epoch 95/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6543 - accuracy: 0.3851\n",
      "Epoch 96/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6574 - accuracy: 0.3863\n",
      "Epoch 97/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6407 - accuracy: 0.3830\n",
      "Epoch 98/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6432 - accuracy: 0.3839\n",
      "Epoch 99/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6330 - accuracy: 0.3991\n",
      "Epoch 100/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 1.6265 - accuracy: 0.3946\n",
      "19/19 - 1s - loss: 2.4587 - accuracy: 0.1614 - 561ms/epoch - 30ms/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 28)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 655)               18995     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 655)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                6560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,555\n",
      "Trainable params: 25,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: class_prediction\\assets\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "build_NN(target, 'class_prediction', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-ancient",
   "metadata": {},
   "source": [
    "## Preparing For Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "clean-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df_decade, features):\n",
    "    df_decade[\"Price_weekly_increase_future\"] = df_decade['Close'].pct_change(periods = -5)\n",
    "    df_decade[\"Close_pct_change\"] = df_decade['Close'].pct_change(periods = 1)\n",
    "    df_decade[\"Volume_daily_increase_past\"] = df_decade['Volume'].pct_change(periods = 1)\n",
    "    df_decade[\"Open_daily_increase_past\"] = df_decade['Open'].pct_change(periods = 1)\n",
    "    df_decade[\"High_daily_increase_past\"] = df_decade['High'].pct_change(periods = 1)\n",
    "    df_decade[\"Low_daily_increase_past\"] = df_decade['Low'].pct_change(periods = 1)\n",
    "\n",
    "    df_decade[\"Close_weekly_increase_past\"] = df_decade['Close'].pct_change(periods = 5)\n",
    "    df_decade[\"Volume_weekly_increase_past\"] = df_decade['Volume'].pct_change(periods = 5)\n",
    "    df_decade[\"Open_weekly_increase_past\"] = df_decade['Open'].pct_change(periods = 5)\n",
    "    df_decade[\"High_weekly_increase_past\"] = df_decade['High'].pct_change(periods = 5)\n",
    "    df_decade[\"Low_weekly_increase_past\"] = df_decade['Low'].pct_change(periods = 5)\n",
    "\n",
    "    df_decade['High_Low_range'] = df_decade[\"High\"] - df_decade[\"Low\"]\n",
    "    df_decade['is_start_week'] = df_decade['Date'].apply(start_week)\n",
    "    df_decade['is_end_week'] = df_decade['Date'].apply(end_week)\n",
    "    \n",
    "    df_decade['is_dividends'] = np.where(df_decade['Dividends'] > 0, 1, 0)\n",
    "    df_decade['is_stock_splits'] = np.where(df_decade['Stock Splits'] > 0, 1, 0)\n",
    "    df_decade['Price_weekly_increase_future'] = df_decade['Price_weekly_increase_future'].apply(lambda x: -1*x)\n",
    "    df_decade['Month'] = df_decade[\"Date\"].apply(lambda x: x.month)\n",
    "    df_dummie_month = pd.get_dummies(df_decade['Month'])\n",
    "    df_dummie_month.columns = [f\"Month_{col}\" for col in df_dummie_month]\n",
    "    df_decade = df_decade.join(df_dummie_month)\n",
    "    return df_decade[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abstract-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicit_to_series(model, X, _array):\n",
    "    predictions = model(X)\n",
    "    top_k_values, top_k_indices = tf.nn.top_k(predictions, k=1)\n",
    "    string_predictions = [_array[i] for i in top_k_indices]\n",
    "    probabilities = [float(i) for i in top_k_values]\n",
    "    return string_predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "smart-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_latest_possible(model, df, _array, features):\n",
    "    latest_date = format_df(df, features = features)[-1:]\n",
    "    _class, probability = predicit_to_series(model, latest_date.values, _array = _array)\n",
    "    return _class, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sapphire-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('class_prediction')\n",
    "\n",
    "new_model_if_increase = tf.keras.models.load_model('if_increase')\n",
    "\n",
    "_array = np.array(['1% - 2%', '2% - 3%', '3%+', 'decrease 1%-2%', 'decrease 2%-3%',\n",
    "       'decrease more that 3%', 'insignificant decrease > -0.1%',\n",
    "       'insignificant increase < 0.1%', 'less than 1% decrease',\n",
    "       'less than 1% increase'])\n",
    "\n",
    "_array_if_increase = np.array([0,1])\n",
    "\n",
    "\n",
    "features = ['Close_pct_change', 'Volume_daily_increase_past',\n",
    "       'Open_daily_increase_past', 'High_daily_increase_past',\n",
    "       'Low_daily_increase_past', 'Close_weekly_increase_past',\n",
    "       'Volume_weekly_increase_past', 'Open_weekly_increase_past',\n",
    "       'High_weekly_increase_past', 'Low_weekly_increase_past',\n",
    "       'High_Low_range', 'is_start_week', 'is_end_week', 'is_dividends',\n",
    "       'is_stock_splits', 'Month', 'Month_1', 'Month_2', 'Month_3', 'Month_4',\n",
    "       'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9', 'Month_10',\n",
    "       'Month_11', 'Month_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "happy-computer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-76441995433c>:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  string_predictions = [_array[i] for i in top_k_indices]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0], [0.7198010683059692])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_latest_possible(model = new_model_if_increase, df = df, _array = _array_if_increase, features = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-tongue",
   "metadata": {},
   "source": [
    "# Strategy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "healthy-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df_decade[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "minor-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-76441995433c>:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  string_predictions = [_array[i] for i in top_k_indices]\n"
     ]
    }
   ],
   "source": [
    "predictions, probabilities = predicit_to_series(new_model, features_df.values, _array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sexual-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-76441995433c>:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  string_predictions = [_array[i] for i in top_k_indices]\n"
     ]
    }
   ],
   "source": [
    "predictions_one, probabilities_one = predicit_to_series(new_model_if_increase, features_df.values, _array_if_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "excessive-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decade['class_prediction'] = predictions\n",
    "df_decade['binary_prediction'] = predictions_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "south-overall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3%+                               940\n",
       "1% - 2%                           725\n",
       "decrease more that 3%             396\n",
       "decrease 1%-2%                    235\n",
       "less than 1% increase             233\n",
       "less than 1% decrease             197\n",
       "2% - 3%                           191\n",
       "decrease 2%-3%                     90\n",
       "insignificant decrease > -0.1%     20\n",
       "insignificant increase < 0.1%       8\n",
       "Name: class_prediction, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decade['class_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "contemporary-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_decade[df_decade['binary_prediction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "hidden-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['class_prediction'] == '3%+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "virgin-syndication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    665\n",
       "0    270\n",
       "Name: did_increase, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['did_increase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "funny-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112299465240641"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['did_increase'].value_counts()[1]/(test_df['did_increase'].value_counts()[0] + test_df['did_increase'].value_counts()[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
